Stereo vision systems allow for depth to be associated with objects within images. However, for real-time stereo vision, a lot of data needs to be processed relatively fast. Real-time stereo vision allows for mobile robots to more easily navigate terrain and interact with objects by providing both the images from the cameras and the depth of the objects from those images. Fortunately the image processing to obtain the depth in images can parallelized in order to speed up the process. Field Programmable Gateway Arrays (FPGAs) are highly parallelizable and lend themselves well to this problem.

This thesis presents a stereo vision module which uses the Sum of Absolute Differences (SAD) algorithm, due to its highly parallel nature, in two different implementations. The SAD algorithm uses windows, or regions of pixels, to compare corresponding pixels to find matching pairs to determine depth. The first implementation uses a 9x9 window for comparison and is able to process 4 pixels simultaneously. The second implementation uses a 7x7 window and processes 2 pixels simultaneously. The 9x9 window implementation creates a better depth image with less noise than the 7x7 window implementation, but the 7x7 version is shown to process images at a higher frame rate. Through simulation, it has been shown for the 9x9 and 7x7 implementations for image pairs of 640x480 to have a frame rate of 11.26 and 16.23, receptively.
