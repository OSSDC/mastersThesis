Stereo vision systems allow for depth to be associated with objects within images. However, for real-time stereo vision, a lot of data needs to be processed relatively quickly. Real-time stereo vision allows for mobile robots to more easily navigate terrain and interact with objects by providing both the images from the cameras and the depth of the objects in those images. Fortunately, the image processing can parallelized in order to increase the processing speed. Field Programmable Gateway Arrays (FPGAs) are highly parallelizable and lend themselves well to this problem.

This thesis presents a stereo vision module which uses the Sum of Absolute Differences (SAD) algorithm. The SAD algorithm uses windows, or regions of pixels, to compare corresponding pixels to find matching pairs to determine depth. Two different implementations are presented that utilize the SAD algorithm's highly parallel nature. The first implementation uses a 9x9 window for comparison and is able to process 4 pixels simultaneously. The second implementation uses a 7x7 window and processes 2 pixels simultaneously, but has a higher degree of parallelism within the SAD algorithm. The 9x9 window implementation creates a better depth image with less noise than the 7x7 window implementation, but the 7x7 version is shown to process images at a higher frame rate. Through simulation, it has been shown for the 9x9 and 7x7 implementations for an image size of 640x480 to have a frame rate of 11.26 and 16.23, receptively.
